{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file created successfully!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "# Initialize the dictionary with an empty messages list.\n",
    "data = {\"messages\": []}\n",
    "\n",
    "# Open and read the CSV file.\n",
    "with open(\"Finance-Data.csv\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        # Create a message object for each row.\n",
    "        message = {\n",
    "            \"role\": row[\"Title\"],\n",
    "            \"content\": row[\"Content\"]\n",
    "        }\n",
    "        data[\"messages\"].append(message)\n",
    "\n",
    "# Write the resulting JSON to an output file.\n",
    "with open(\"output.json\", \"w\", encoding=\"utf-8\") as jsonfile:\n",
    "    json.dump(data, jsonfile, indent=4)\n",
    "\n",
    "print(\"JSON file created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and Validation JSON files created successfully!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "# Read all messages from the CSV file\n",
    "messages = []\n",
    "with open(\"Finance-Data.csv\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        message = {\n",
    "            \"role\": row[\"Title\"],\n",
    "            \"content\": row[\"Content\"]\n",
    "        }\n",
    "        messages.append(message)\n",
    "\n",
    "# Define the number of validation instances\n",
    "num_validation = 40\n",
    "\n",
    "# Split messages into validation and training sets.\n",
    "validation_messages = messages[:num_validation]\n",
    "training_messages = messages[num_validation:]\n",
    "\n",
    "# Write training data to a separate file\n",
    "with open(\"training.json\", \"w\", encoding=\"utf-8\") as train_file:\n",
    "    json.dump({\"messages\": training_messages}, train_file, indent=4)\n",
    "\n",
    "# Write validation data to a separate file\n",
    "with open(\"validation.json\", \"w\", encoding=\"utf-8\") as valid_file:\n",
    "    json.dump({\"messages\": validation_messages}, valid_file, indent=4)\n",
    "\n",
    "print(\"Training and Validation JSON files created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and Validation JSONL files created successfully!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "# Read all messages from the CSV file\n",
    "messages = []\n",
    "with open(\"Finance-Data.csv\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        message = {\n",
    "            \"role\": row[\"Title\"],\n",
    "            \"content\": row[\"Content\"]\n",
    "        }\n",
    "        messages.append(message)\n",
    "\n",
    "# Define the number of validation instances\n",
    "num_validation = 40\n",
    "\n",
    "# Split messages into validation and training sets.\n",
    "validation_messages = messages[:num_validation]\n",
    "training_messages = messages[num_validation:]\n",
    "\n",
    "# Write training messages in JSONL format\n",
    "with open(\"training.jsonl\", \"w\", encoding=\"utf-8\") as train_file:\n",
    "    for message in training_messages:\n",
    "        train_file.write(json.dumps(message) + \"\\n\")\n",
    "\n",
    "# Write validation messages in JSONL format\n",
    "with open(\"validation.jsonl\", \"w\", encoding=\"utf-8\") as valid_file:\n",
    "    for message in validation_messages:\n",
    "        valid_file.write(json.dumps(message) + \"\\n\")\n",
    "\n",
    "print(\"Training and Validation JSONL files created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and validation JSONL files created successfully!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "# Read all messages from the CSV file.\n",
    "# Here, we assume each row in the CSV represents a complete conversation with one message.\n",
    "# If you have multi-turn conversations, you'll need to group rows by conversation ID or a similar field.\n",
    "conversations = []\n",
    "with open(\"Finance-Data.csv\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        # Each conversation is stored as a JSON object with a \"messages\" array.\n",
    "        conversation = {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": row[\"Title\"],\n",
    "                    \"content\": row[\"Content\"]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        conversations.append(conversation)\n",
    "\n",
    "# Define the number of validation instances (first 40 instances for validation).\n",
    "num_validation = 40\n",
    "validation_conversations = conversations[:num_validation]\n",
    "training_conversations = conversations[num_validation:]\n",
    "\n",
    "# Write training conversations to a JSONL file.\n",
    "with open(\"training.jsonl\", \"w\", encoding=\"utf-8\") as train_file:\n",
    "    for conv in training_conversations:\n",
    "        train_file.write(json.dumps(conv) + \"\\n\")\n",
    "\n",
    "# Write validation conversations to a JSONL file.\n",
    "with open(\"validation.jsonl\", \"w\", encoding=\"utf-8\") as valid_file:\n",
    "    for conv in validation_conversations:\n",
    "        valid_file.write(json.dumps(conv) + \"\\n\")\n",
    "\n",
    "print(\"Training and validation JSONL files created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and validation JSONL files created successfully!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "# Allowed enum values for roles.\n",
    "valid_roles = {\"user\", \"system\", \"assistant\"}\n",
    "\n",
    "# File paths (update these if necessary)\n",
    "csv_file_path = \"Finance-Data.csv\"\n",
    "training_output_path = \"training.jsonl\"\n",
    "validation_output_path = \"validation.jsonl\"\n",
    "\n",
    "# Initialize list to hold conversation objects\n",
    "conversations = []\n",
    "\n",
    "# Read CSV file and build conversation objects\n",
    "with open(csv_file_path, newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        # Get the role from the Title column\n",
    "        role = row.get(\"Title\", \"\").strip()\n",
    "        # If the role is not valid, default to \"assistant\" (you can adjust this default as needed)\n",
    "        if role not in valid_roles:\n",
    "            role = \"assistant\"\n",
    "        # Ensure Content is present\n",
    "        content = row.get(\"Content\", \"\").strip()\n",
    "        if not content:\n",
    "            continue  # Skip rows with empty content\n",
    "        # Build the conversation object with a \"messages\" array\n",
    "        conversation = {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": role,\n",
    "                    \"content\": content\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        conversations.append(conversation)\n",
    "\n",
    "# Define the number of validation instances (first 40 rows will be validation)\n",
    "num_validation = 40\n",
    "validation_conversations = conversations[:num_validation]\n",
    "training_conversations = conversations[num_validation:]\n",
    "\n",
    "# Write training JSONL file\n",
    "with open(training_output_path, \"w\", encoding=\"utf-8\") as train_file:\n",
    "    for conv in training_conversations:\n",
    "        # Check that the messages array has at least one message object\n",
    "        if conv.get(\"messages\") and isinstance(conv[\"messages\"], list) and len(conv[\"messages\"]) >= 1:\n",
    "            train_file.write(json.dumps(conv) + \"\\n\")\n",
    "\n",
    "# Write validation JSONL file\n",
    "with open(validation_output_path, \"w\", encoding=\"utf-8\") as valid_file:\n",
    "    for conv in validation_conversations:\n",
    "        if conv.get(\"messages\") and isinstance(conv[\"messages\"], list) and len(conv[\"messages\"]) >= 1:\n",
    "            valid_file.write(json.dumps(conv) + \"\\n\")\n",
    "\n",
    "print(\"Training and validation JSONL files created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"training.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for i, line in enumerate(f, 1):\n",
    "        try:\n",
    "            data = json.loads(line)\n",
    "            if not isinstance(data, dict):\n",
    "                print(f\"Line {i} is not a JSON object.\")\n",
    "            elif \"messages\" not in data:\n",
    "                print(f\"Line {i} missing 'messages' key.\")\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Line {i} JSON error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "def csv_to_jsonl(csv_file, training_file, validation_file, num_validation=40):\n",
    "    # Read all rows from the CSV file\n",
    "    with open(csv_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        rows = list(reader)\n",
    "\n",
    "    # Split data: first num_validation rows go to validation, rest go to training\n",
    "    validation_data = rows[:num_validation]\n",
    "    training_data = rows[num_validation:]\n",
    "\n",
    "    # Write validation data to validation_file in .jsonl format\n",
    "    with open(validation_file, \"w\", encoding=\"utf-8\") as val_f:\n",
    "        for row in validation_data:\n",
    "            # Here we force the role to be \"assistant\" (valid for OpenAI),\n",
    "            # and place Title + Content in content.\n",
    "            messages = [\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": f\"{row['Title']}\\n\\n{row['Content']}\"\n",
    "                }\n",
    "            ]\n",
    "            # Dump a single JSON object per line\n",
    "            val_f.write(json.dumps({\"messages\": messages}, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    # Write training data to training_file in .jsonl format\n",
    "    with open(training_file, \"w\", encoding=\"utf-8\") as train_f:\n",
    "        for row in training_data:\n",
    "            messages = [\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": f\"{row['Title']}\\n\\n{row['Content']}\"\n",
    "                }\n",
    "            ]\n",
    "            train_f.write(json.dumps({\"messages\": messages}, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # File paths (adjust as needed)\n",
    "    input_csv = \"data.csv\"\n",
    "    output_training_jsonl = \"training.jsonl\"\n",
    "    output_validation_jsonl = \"validation.jsonl\"\n",
    "\n",
    "    csv_to_jsonl(\n",
    "        csv_file=input_csv,\n",
    "        training_file=output_training_jsonl,\n",
    "        validation_file=output_validation_jsonl,\n",
    "        num_validation=40  # number of rows to use for validation\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
